{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-ZC Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded both CSV files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "csv_path = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank\"\n",
    "\n",
    "# File paths for the CSVs\n",
    "bank_full_csv = os.path.join(csv_path, \"bank-full.csv\")\n",
    "bank_csv = os.path.join(csv_path, \"bank.csv\")\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "try:\n",
    "    bank_full_df = pd.read_csv(bank_full_csv, sep=';')  # Assuming semicolon separator based on UCI datasets\n",
    "    bank_df = pd.read_csv(bank_csv, sep=';')            # Adjust the separator if needed\n",
    "\n",
    "    print(\"Successfully loaded both CSV files.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "balance      0\n",
      "housing      0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "Final check for missing values:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "balance      0\n",
      "housing      0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Columns to extract\n",
    "columns_to_extract = [\n",
    "    \"age\", \"job\", \"marital\", \"education\", \"balance\", \"housing\", \n",
    "    \"contact\", \"day\", \"month\", \"duration\", \"campaign\", \"pdays\", \n",
    "    \"previous\", \"poutcome\", \"y\"\n",
    "]\n",
    "\n",
    "# Extract only the specified columns\n",
    "bank_full_selected = bank_full_df[columns_to_extract]\n",
    "\n",
    "# Check for missing values (NaNs)\n",
    "print(\"Checking for missing values:\")\n",
    "print(bank_full_selected.isnull().sum())\n",
    "\n",
    "# Handling missing values\n",
    "# For numerical columns, replace NaNs with the median\n",
    "numerical_columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
    "for column in numerical_columns:\n",
    "    if bank_full_selected[column].isnull().sum() > 0:\n",
    "        median_value = bank_full_selected[column].median()\n",
    "        bank_full_selected[column].fillna(median_value, inplace=True)\n",
    "        print(f\"Missing values in {column} replaced with median value {median_value}.\")\n",
    "\n",
    "# For categorical columns, replace NaNs with the mode (most frequent value)\n",
    "categorical_columns = [\"job\", \"marital\", \"education\", \"housing\", \"contact\", \"month\", \"poutcome\", \"y\"]\n",
    "for column in categorical_columns:\n",
    "    if bank_full_selected[column].isnull().sum() > 0:\n",
    "        mode_value = bank_full_selected[column].mode()[0]\n",
    "        bank_full_selected[column].fillna(mode_value, inplace=True)\n",
    "        print(f\"Missing values in {column} replaced with mode value {mode_value}.\")\n",
    "\n",
    "# Final check for missing values\n",
    "print(\"Final check for missing values:\")\n",
    "print(bank_full_selected.isnull().sum())\n",
    "\n",
    "# bank_full_selected now has the specified columns and missing values handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent observation (mode) for the 'education' column is: secondary\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Get the mode (most frequent observation) for the 'education' column\n",
    "education_mode = bank_full_df['education'].mode()[0]\n",
    "\n",
    "print(f\"The most frequent observation (mode) for the 'education' column is: {education_mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n",
      "\n",
      "Two features with the highest correlation:\n",
      "previous  pdays       0.45482\n",
      "pdays     previous    0.45482\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = bank_full_df[[\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]]\n",
    "\n",
    "# Create the correlation matrix\n",
    "correlation_matrix = numerical_features.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Find the two features with the highest correlation\n",
    "correlation_pairs = correlation_matrix.unstack()\n",
    "sorted_pairs = correlation_pairs.sort_values(ascending=False)\n",
    "\n",
    "# Exclude self-correlation (correlation of a feature with itself)\n",
    "sorted_pairs = sorted_pairs[sorted_pairs < 1]\n",
    "\n",
    "# Get the top two correlated features\n",
    "top_two = sorted_pairs.head(2)\n",
    "\n",
    "print(\"\\nTwo features with the highest correlation:\")\n",
    "print(top_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 27126 samples\n",
      "Validation set size: 9042 samples\n",
      "Test set size: 9043 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Replace 'yes'/'no' with 1/0 in the target column 'y'\n",
    "bank_full_df['y'] = bank_full_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = bank_full_df.drop(columns=['y'])  # Features\n",
    "y = bank_full_df['y']                  # Target\n",
    "\n",
    "# Split the data into train and temp (20% for validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Now split the temp into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Output the sizes of each set\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "contact: 0.0\n",
      "education: 0.0\n",
      "housing: 0.01\n",
      "poutcome: 0.0\n",
      "\n",
      "The variable with the highest mutual information score is 'housing' with a score of 0.01.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Replace 'yes'/'no' with 1/0 in the target column 'y'\n",
    "bank_full_df['y'] = bank_full_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = bank_full_df.drop(columns=['y'])  # Features\n",
    "y = bank_full_df['y']                  # Target\n",
    "\n",
    "# Split the data into train and temp (40% for validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "# Calculate mutual information scores for categorical variables\n",
    "# Select categorical variables of interest after one-hot encoding\n",
    "categorical_vars = ['contact', 'education', 'housing', 'poutcome']\n",
    "\n",
    "# Initialize a dictionary to store mutual information scores\n",
    "mi_scores = {}\n",
    "\n",
    "for var in categorical_vars:\n",
    "    # Create a DataFrame with the encoded variable and target\n",
    "    var_encoded = X_train_encoded.filter(like=var)  # Get one-hot encoded columns for the variable\n",
    "    # Calculate mutual information score\n",
    "    mi_score = mutual_info_classif(var_encoded, y_train, discrete_features=True)\n",
    "    # Store the rounded score\n",
    "    mi_scores[var] = round(mi_score[0], 2)\n",
    "\n",
    "# Display the mutual information scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "for var, score in mi_scores.items():\n",
    "    print(f\"{var}: {score}\")\n",
    "\n",
    "# Identify the variable with the highest mutual information score\n",
    "max_var = max(mi_scores, key=mi_scores.get)\n",
    "max_score = mi_scores[max_var]\n",
    "\n",
    "print(f\"\\nThe variable with the highest mutual information score is '{max_var}' with a score of {max_score}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation dataset: 0.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Replace 'yes'/'no' with 1/0 in the target column 'y'\n",
    "bank_full_df['y'] = bank_full_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = bank_full_df.drop(columns=['y'])  # Features\n",
    "y = bank_full_df['y']                  # Target\n",
    "\n",
    "# Split the data into train and temp (40% for validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# One-hot encode the categorical variables for training and validation sets\n",
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(X_val, drop_first=True)\n",
    "\n",
    "# Align the training and validation dataframes to have the same columns\n",
    "X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Fit the Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val_encoded)\n",
    "\n",
    "# Calculate accuracy on the validation dataset\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Round the accuracy to 2 decimal digits\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "print(f\"Accuracy on the validation dataset: {accuracy_rounded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Differences:\n",
      "age: 0.0\n",
      "balance: -0.0\n",
      "marital: Feature not found in the model.\n",
      "previous: 0.0\n",
      "\n",
      "The feature with the smallest difference in accuracy is 'age' with a difference of 0.0.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Replace 'yes'/'no' with 1/0 in the target column 'y'\n",
    "bank_full_df['y'] = bank_full_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = bank_full_df.drop(columns=['y'])  # Features\n",
    "y = bank_full_df['y']                  # Target\n",
    "\n",
    "# Split the data into train and temp (40% for validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# One-hot encode the categorical variables for training and validation sets\n",
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(X_val, drop_first=True)\n",
    "\n",
    "# Align the validation DataFrame to have the same columns as the training DataFrame\n",
    "X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Fit the Logistic Regression model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions and calculate the original accuracy\n",
    "y_val_pred = model.predict(X_val_encoded)\n",
    "original_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Initialize a dictionary to store accuracy differences\n",
    "accuracy_differences = {}\n",
    "\n",
    "# List of features to exclude\n",
    "features_to_exclude = ['age', 'balance', 'marital', 'previous']\n",
    "\n",
    "for feature in features_to_exclude:\n",
    "    # Check if the feature exists in the columns of X_train_encoded\n",
    "    if feature in X_train_encoded.columns:\n",
    "        # Create a new DataFrame without the feature\n",
    "        X_train_excluded = X_train_encoded.drop(columns=[feature])\n",
    "        X_val_excluded = X_val_encoded.drop(columns=[feature])\n",
    "        \n",
    "        # Fit the model without the excluded feature\n",
    "        model.fit(X_train_excluded, y_train)\n",
    "        \n",
    "        # Make predictions and calculate accuracy without the feature\n",
    "        y_val_pred_excluded = model.predict(X_val_excluded)\n",
    "        new_accuracy = accuracy_score(y_val, y_val_pred_excluded)\n",
    "        \n",
    "        # Calculate the difference and store it\n",
    "        accuracy_difference = round(original_accuracy - new_accuracy, 2)\n",
    "        accuracy_differences[feature] = accuracy_difference\n",
    "    else:\n",
    "        # If the feature is not present, note that in the output\n",
    "        accuracy_differences[feature] = None\n",
    "\n",
    "# Display the accuracy differences\n",
    "print(\"Accuracy Differences:\")\n",
    "for feature, difference in accuracy_differences.items():\n",
    "    if difference is not None:\n",
    "        print(f\"{feature}: {difference}\")\n",
    "    else:\n",
    "        print(f\"{feature}: Feature not found in the model.\")\n",
    "\n",
    "# Identify the feature with the smallest difference\n",
    "# Exclude None values for finding the minimum\n",
    "filtered_differences = {k: v for k, v in accuracy_differences.items() if v is not None}\n",
    "least_useful_feature = min(filtered_differences, key=filtered_differences.get)\n",
    "smallest_difference = filtered_differences[least_useful_feature]\n",
    "\n",
    "print(f\"\\nThe feature with the smallest difference in accuracy is '{least_useful_feature}' with a difference of {smallest_difference}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Results for different C values:\n",
      "C=0.01: Accuracy=0.898\n",
      "C=0.1: Accuracy=0.901\n",
      "C=1: Accuracy=0.902\n",
      "C=10: Accuracy=0.901\n",
      "C=100: Accuracy=0.901\n",
      "\n",
      "The best C value is 1 with an accuracy of 0.902.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the bank-full.csv file\n",
    "bank_full_csv = \"/Users/sebastianreyes/Documents/3 Carrera/Proyectos/Portafolio/machinelearning_zoomcamp/bank+marketing/bank/bank-full.csv\"\n",
    "bank_full_df = pd.read_csv(bank_full_csv, sep=';')\n",
    "\n",
    "# Replace 'yes'/'no' with 1/0 in the target column 'y'\n",
    "bank_full_df['y'] = bank_full_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = bank_full_df.drop(columns=['y'])  # Features\n",
    "y = bank_full_df['y']                  # Target\n",
    "\n",
    "# Split the data into train and temp (40% for validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# One-hot encode the categorical variables for training and validation sets\n",
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(X_val, drop_first=True)\n",
    "\n",
    "# Align the validation DataFrame to have the same columns as the training DataFrame\n",
    "X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# List of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "accuracy_results = {}\n",
    "\n",
    "# Train a model for each value of C and evaluate accuracy\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val_encoded)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracy_results[C] = round(accuracy, 3)\n",
    "\n",
    "# Display the accuracy results for each C value\n",
    "print(\"Accuracy Results for different C values:\")\n",
    "for C, accuracy in accuracy_results.items():\n",
    "    print(f\"C={C}: Accuracy={accuracy}\")\n",
    "\n",
    "# Identify the C value with the best accuracy\n",
    "best_C = max(accuracy_results, key=accuracy_results.get)\n",
    "best_accuracy = accuracy_results[best_C]\n",
    "\n",
    "print(f\"\\nThe best C value is {best_C} with an accuracy of {best_accuracy}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
